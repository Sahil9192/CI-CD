import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, precision_recall_curve, auc
import numpy as np
import os

# Step 1: Load the Breast Cancer dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Step 2: Split into train/test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Train Logistic Regression model
lr_model = LogisticRegression(max_iter=10000)
lr_model.fit(X_train, y_train)

# Step 4: Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)

# Step 5: Make predictions
lr_pred = lr_model.predict(X_test)
rf_pred = rf_model.predict(X_test)

# Step 6: Create confusion matrix for Logistic Regression
cm_lr = confusion_matrix(y_test, lr_pred)

# Step 7: Create confusion matrix for Random Forest
cm_rf = confusion_matrix(y_test, rf_pred)

# Step 8: Plot confusion matrix for Logistic Regression
plt.figure(figsize=(5, 4))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('results/confusion_matrix_lr.png')  # Save to file
plt.show()

# Step 9: Plot confusion matrix for Random Forest
plt.figure(figsize=(5, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('results/confusion_matrix_rf.png')  # Save to file
plt.show()

# Step 10: Plot Precision-Recall curve for Logistic Regression
y_scores_lr = lr_model.predict_proba(X_test)[:, 1]  # Get probabilities for positive class
precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_scores_lr)
plt.figure(figsize=(6, 5))
plt.plot(recall_lr, precision_lr, color='blue', label='Logistic Regression')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve - Logistic Regression')
plt.legend()
plt.savefig('results/precision_recall_lr.png')  # Save to file
plt.show()

# Step 11: Plot Precision-Recall curve for Random Forest
y_scores_rf = rf_model.predict_proba(X_test)[:, 1]  # Get probabilities for positive class
precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_scores_rf)
plt.figure(figsize=(6, 5))
plt.plot(recall_rf, precision_rf, color='green', label='Random Forest')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve - Random Forest')
plt.legend()
plt.savefig('results/precision_recall_rf.png')  # Save to file
plt.show()

# Step 12: Compare models using accuracy
lr_accuracy = lr_model.score(X_test, y_test)
rf_accuracy = rf_model.score(X_test, y_test)

print(f"Logistic Regression Accuracy: {lr_accuracy:.2f}")
print(f"Random Forest Accuracy: {rf_accuracy:.2f}")

# Step 13: Compare models - Which one is better?
if lr_accuracy > rf_accuracy:
    print("Logistic Regression performs better.")
else:
    print("Random Forest performs better.")
